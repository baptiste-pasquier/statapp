{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (GridSearchCV, ParameterGrid,\n",
    "                                     RandomizedSearchCV)\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from imblearn.pipeline import Pipeline as Pipeline_imb\n",
    "from imblearn.over_sampling import SMOTENC, RandomOverSampler\n",
    "from tools import (COLUMNS_QUANT, COLUMNS_CAT,\n",
    "                   Modelisation, datasets, SearchCV, restauration_CV, \n",
    "                   graph_2scores_CV, graph_3scores_CV, graph_param_CV, \n",
    "                   best_score_CV)\n",
    "\n",
    "## Matplotlib : \n",
    "# Pour affichage interactif (notamment 3D) dans notebook\n",
    "# %matplotlib widget\n",
    "\n",
    "# Pour affichage interactif (notamment 3D) dans une fenêtre qt externe au notebook\n",
    "# %matplotlib qt\n",
    "\n",
    "# Pour affichage simple dans notebook\n",
    "# %config InlineBackend.figure_format = 'png'\n",
    "\n",
    "t = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/df_train_prepro.csv').sample(frac=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Définition des variables quantitatives, des variables catégorielles et des datasets :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_df = datasets(df)\n",
    "X_quant = datasets_df['X_quant']\n",
    "X_cat = datasets_df['X_cat']\n",
    "X = datasets_df['X']\n",
    "y = datasets_df['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de comparer nos modèles en termes de performances brutes et de temps d'exécution, il est fondamental de déterminer quelques métriques de référence. Ici, il faut surtout faire en sorte d'éviter de prédire des non-clics qui seraient en réalité des clics (ie prédire trop de 0), quitte à prédire trop de 1. Autrement dit, il faut maximiser le recall et le NPV (Negative predictive value) afin de limiter les erreurs de type II. Le F1 Score, combinaison du recall et de la précision, est également pertinent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression logistique\n",
    "## Variables quantitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X_quant, y, LogisticRegression(), scaling=True)\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.show_ROC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(np.transpose(m.model.coef_), X_quant.columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problème :** pas de scaling dans la cellule suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from statsmodels.tools import add_constant\n",
    "\n",
    "X_quant_scaled = datasets_df['X_quant_scaled']\n",
    "X_ = add_constant(X_quant_scaled)\n",
    "print(Logit(y, X_).fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec LASSO (+ univariate mais variable déjà exclue par Lasso): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df[['contextid',\n",
    "         'zonecostineuro',\n",
    "         'campaignctrlast24h',\n",
    "         'ltf_nbpartnerclick_90d',\n",
    "         'nbdisplay_1hour',\n",
    "         'nbdayssincelastclick',\n",
    "         'display_size',\n",
    "         'nbdisplayglobalapprox_1d_sum_xdevice']]\n",
    "y1 = df['is_display_clicked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = Modelisation(X1, y1, LogisticRegression(), scaling=True)\n",
    "m1.show_conf_matrix()\n",
    "m1.show_metrics_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de valeurs distinctes\n",
    "from tools import COLUMNS_CAT\n",
    "for column in COLUMNS_CAT:\n",
    "    print(f\"{column} : {len(set(df[column]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X_cat, y, LogisticRegression(), scaling=True)\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables quantitatives + catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X, y, LogisticRegression(), scaling=True)\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X, y, LogisticRegression(class_weight='balanced'), scaling=True)\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec RFECV :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X[['zonecostineuro',\n",
    "         'campaignctrlast24h',\n",
    "         'nbdisplay_1hour',\n",
    "         'nbdayssincelastclick',\n",
    "         'display_size',\n",
    "         'is_interstitial_True',\n",
    "         'device_type_Desktop',\n",
    "         'device_type_iPhone',\n",
    "         'display_env_app_ios',\n",
    "         'target_env_2',\n",
    "         'campaignscenario_13']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = Modelisation(X2, y, LogisticRegression(), scaling=True)\n",
    "m2.show_conf_matrix()\n",
    "m2.show_metrics_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison par rapport aux valeurs de C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X, y, LogisticRegression(C=0.2), scaling=True)\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "C, list_recall = [], []\n",
    "for c in np.logspace(-5.5, 5.5, num=11): \n",
    "    m = Modelisation(X, y, LogisticRegression(C=c), scaling=True)\n",
    "    C.append(c)\n",
    "    list_recall.append(m.recall)\n",
    "plt.plot(C, list_recall)\n",
    "plt.xscale('log')\n",
    "plt.title(\"Recall de la régression logistique en fonction des valeurs de C\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning des hyperparamètres avec GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "cv_params = {\n",
    "        \"C\": np.logspace(-5, 4, 50),\n",
    "        \"class_weight\": [None, 'balanced', {0:1, 1:2}, {0:1, 1:4}, {0:1, 1:8}, {0:1, 1:10}, {0:1, 1:12}, {0:1, 1:14}, {0:1, 1:16.5}] \n",
    "        }\n",
    "\n",
    "scoring = {'recall': 'recall',\n",
    "           'precision': 'precision',\n",
    "           'f1': 'f1',\n",
    "           'f3': make_scorer(fbeta_score, beta=3),\n",
    "           'f5': make_scorer(fbeta_score, beta=5)\n",
    "          }\n",
    "\n",
    "print(len(ParameterGrid(cv_params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SearchCV(model, cv_params, data_frac=1, scaling=True, scoring=scoring, random=False, n_jobs=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico, results = restauration_CV('LR_CV_Grid_450_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV(dico, results, 'recall', 'f1', s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV(dico, results, 'recall', 'precision', s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_3scores_CV(dico, results, 'recall', 'precision', 'f1', s=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_3scores_CV(dico, results, 'f1', 'f3', 'f5', s=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_param_CV(dico, results, xscale={'C': 'log'}, ncols=2, height=5, width=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best_score_CV(dico, results, 'f5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X, y, LogisticRegression(**best_params), scaling=True)\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression logistique avec sur-échantillonnage\n",
    "\n",
    "**/!\\ : Seule la base de training est sur-échantillonnée.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/df_train_prepro.csv').sample(frac=0.05)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_df = datasets(df, verbose=False)\n",
    "X = datasets_df['X']\n",
    "y = datasets_df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = list(range(len(COLUMNS_QUANT), len(X.columns)))\n",
    "print(categorical_features)\n",
    "\n",
    "over = SMOTENC(categorical_features=categorical_features, \n",
    "              sampling_strategy=1, \n",
    "              k_neighbors=5,\n",
    "              random_state=1234)\n",
    "\n",
    "pipeline = Pipeline_imb([\n",
    "            ('over', over),\n",
    "            ('classifier', LogisticRegression())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X, y, pipeline, scaling=True)\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = RandomOverSampler(sampling_strategy=1, random_state=1234)\n",
    "\n",
    "pipeline = Pipeline_imb([\n",
    "            ('over', over),\n",
    "            ('classifier', LogisticRegression())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X, y, pipeline, scaling=True)\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = RandomOverSampler(random_state=1234)\n",
    "\n",
    "pipeline = Pipeline_imb([\n",
    "            ('over', over),\n",
    "            ('model', LogisticRegression())\n",
    "            ])\n",
    "\n",
    "cv_params = {\n",
    "        \"over__sampling_strategy\": [0.2, 0.4, 0.6, 0.8, 1],\n",
    "        \"model__C\": np.logspace(-5, 4, 50),\n",
    "        \"model__class_weight\": [None, 'balanced', {0:1, 1:2}, {0:1, 1:4}, {0:1, 1:8}, {0:1, 1:10}, {0:1, 1:12}, {0:1, 1:14}, {0:1, 1:16.5}] \n",
    "        }\n",
    "\n",
    "print(len(ParameterGrid(cv_params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SearchCV(pipeline, cv_params, data_frac=1, scaling=True, random=False, scoring=scoring, n_jobs=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico, results = restauration_CV('RandomOver_LR_CV_Grid_2250_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV(dico, results, 'recall', 'f1', s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV(dico, results, 'recall', 'precision', s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_3scores_CV(dico, results, 'recall', 'precision', 'f1', s=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_3scores_CV(dico, results, 'f1', 'f3', 'f5', s=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_param_CV(dico, results, xscale={'C': 'log'}, ncols=2, height=5, width=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best_score_CV(dico, results, 'f5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X, y, pipeline.set_params(**best_params), scaling=True)\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Temps d'exécution total : {time.strftime('%H:%M:%S', time.gmtime(time.time()-t))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import (GridSearchCV, ParameterGrid,\n",
    "                                     RandomizedSearchCV)\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import random\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from imblearn.pipeline import Pipeline as Pipeline_imb\n",
    "from imblearn.over_sampling import SMOTENC, RandomOverSampler\n",
    "from tools import (Modelisation, datasets, SearchCV, restauration_CV, \n",
    "                   graph_2scores_CV, graph_3scores_CV, graph_param_CV, \n",
    "                   best_score_CV, graph_2scores_CV_comp)\n",
    "import json\n",
    "\n",
    "## Matplotlib : \n",
    "# Pour affichage interactif (notamment 3D) dans notebook\n",
    "# %matplotlib widget\n",
    "\n",
    "# Pour affichage interactif (notamment 3D) dans une fenêtre qt externe au notebook\n",
    "# %matplotlib qt\n",
    "\n",
    "# Pour affichage simple dans notebook\n",
    "# %config InlineBackend.figure_format = 'png'\n",
    "\n",
    "t = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/df_train_prepro.csv').sample(frac=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Définition des variables quantitatives, des variables catégorielles et des datasets :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_df = datasets(df)\n",
    "X_quant = datasets_df['X_quant']\n",
    "X_cat = datasets_df['X_cat']\n",
    "X = datasets_df['X']\n",
    "y = datasets_df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y[y == 0]) / (len(y[y == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Modèle brut\n",
    "### 1.1. Variables quantitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X_quant, y, XGBClassifier(n_jobs=-1))\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.show_ROC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage d'un arbre (par défaut le premier parmi les autres) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.show_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Variables catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X_cat, y, XGBClassifier(n_jobs=-1))\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.show_ROC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "m.plot_importance(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.show_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Variables quantitatives + catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X, y, XGBClassifier(n_jobs=-1))\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.show_ROC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "m.plot_importance(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.show_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tuning des hyperparamètres avec GridSearchCV\n",
    "\n",
    "On calcule le GridSearchCV sur un dataset plus petit pour avoir un temps de calcul raisonnable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Calcul et sauvegarde\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(booster='gbtree', objective='binary:logistic', n_jobs=1)\n",
    "\n",
    "cv_params = {\n",
    "        'n_estimators': [50, 100, 150, 200, 300],    \n",
    "        'max_depth': [2, 4, 6, 8, 10],\n",
    "        'learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'min_child_weight': [1, 3, 5, 10],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],    \n",
    "        'scale_pos_weight': [1, 16.5]   # A typical value to consider: sum(negative instances) / sum(positive instances)\n",
    "        }\n",
    "\n",
    "print(len(ParameterGrid(cv_params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SearchCV(model, cv_params, data_frac=0.02, random=True, n_iter=10000, random_state=1234, n_jobs=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Restauration des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico, results = restauration_CV('XGBoost_CV_Randomized10000_54000_0.02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graphiques XY avec 2 scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV(dico, results, 'recall', 'f1', s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV(dico, results, 'recall', 'f1', s=20, zoom=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV(dico, results, 'recall', 'f3', s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV(dico, results, 'recall', 'f5', s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV(dico, results, 'recall', 'precision', s=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graphique 3D avec 3 scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_3scores_CV(dico, results, 'recall', 'precision', 'f1', s=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_3scores_CV(dico, results, 'f1', 'f3', 'f5', s=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graphiques de l'effet des paramètres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_param_CV(dico, results, ncols=2, height=3.5, width=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paramètres donnant le meilleur score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best_score_CV(dico, results, 'f3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params['n_jobs'] = -1\n",
    "PARAMS = {}\n",
    "PARAMS[dico['model_name']] = best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyse sur la base complète**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X, y, XGBClassifier(**best_params))\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons avec le `learning_rate` par défaut :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'learning_rate' in best_params:\n",
    "    del best_params['learning_rate']\n",
    "m = Modelisation(X, y, XGBClassifier(**best_params))\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous reproduisons le graphique f1 vs recall en prenant 10% des meilleures combinaisons (selon le recall), en fittant le modèle sur 10% des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_small = pd.read_csv('data/df_train_prepro.csv').sample(frac=0.1)\n",
    "datasets_df_small = datasets(df_small, verbose=False)\n",
    "X_small = datasets_df_small['X']\n",
    "y_small = datasets_df_small['y']\n",
    "\n",
    "f1_list = []\n",
    "recall_list = []\n",
    "params_list = []\n",
    "\n",
    "\n",
    "results_sort = results.sort_values(by=f'mean_test_recall', ascending=False)\n",
    "\n",
    "\n",
    "nb_tot = int(0.10 * len(results))\n",
    "nb = 25\n",
    "\n",
    "random.seed(1)\n",
    "sample = random.sample(list(range(nb_tot)), nb)\n",
    "for j in trange(nb):\n",
    "    i = sample[j]\n",
    "    params = results_sort.iloc[i].params\n",
    "    m = Modelisation(X_small, y_small, XGBClassifier(**params))\n",
    "    params_list.append(params)\n",
    "    f1_list.append(m.metrics_score['f1'])\n",
    "    recall_list.append(m.metrics_score['recall'])\n",
    "    \n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(recall_list, f1_list, marker='o')\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('f1')\n",
    "plt.show()\n",
    " \n",
    "# dico_ = {'params': params_list, 'f1': f1_list, 'recall': recall_list}     \n",
    "# r = pd.DataFrame(dico_).sort_values(by='recall', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même graphique avec le `learning_rate` par défaut :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sample = random.sample(list(range(nb_tot)), nb)\n",
    "for j in trange(nb):\n",
    "    i = sample[j]\n",
    "    params = results_sort.iloc[i].params\n",
    "    if 'learning_rate' in params:\n",
    "        del params['learning_rate']\n",
    "    m = Modelisation(X_small, y_small, XGBClassifier(**params))\n",
    "    params_list.append(params)\n",
    "    f1_list.append(m.metrics_score['f1'])\n",
    "    recall_list.append(m.metrics_score['recall'])\n",
    "    \n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(recall_list, f1_list, marker='o')\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('f1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test de paramètres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'colsample_bytree': 1.0, \n",
    "          'gamma': 1,\n",
    "          'min_child_weight': 15,\n",
    "          'scale_pos_weight': 16.5, \n",
    "          'subsample': 0.8,\n",
    "          'n_jobs': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X, y, XGBClassifier(**params))\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost avec oversampling\n",
    "\n",
    "### 3.1. GridSearchCV avec RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = RandomOverSampler(random_state=1234)\n",
    "\n",
    "pipeline = Pipeline_imb([\n",
    "            ('over', over),\n",
    "            ('model', XGBClassifier(booster='gbtree', objective='binary:logistic', n_jobs=1))\n",
    "            ])\n",
    "\n",
    "cv_params = {\n",
    "        \"over__sampling_strategy\": [0.1, 0.2, 0.4, 0.6, 0.8, 1],\n",
    "        \"model__n_estimators\": [50, 100, 150, 200, 300],    \n",
    "        \"model__max_depth\": [2, 4, 6, 8, 10],\n",
    "        \"model__learning_rate\": [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "        \"model__gamma\": [0.5, 1, 1.5, 2, 5],\n",
    "        \"model__min_child_weight\": [1, 3, 5, 10],\n",
    "        \"model__subsample\": [0.6, 0.8, 1.0],\n",
    "        \"model__colsample_bytree\": [0.6, 0.8, 1.0],    \n",
    "        \"model__scale_pos_weight\": [1, 16.5]   # A typical value to consider: sum(negative instances) / sum(positive instances)\n",
    "        }\n",
    "\n",
    "scoring = {'recall': 'recall',\n",
    "           'precision': 'precision',\n",
    "           'f1': 'f1',\n",
    "           'f3': make_scorer(fbeta_score, beta=3),\n",
    "           'f5': make_scorer(fbeta_score, beta=5)\n",
    "          }\n",
    "\n",
    "print(len(ParameterGrid(cv_params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SearchCV(pipeline, cv_params, data_frac=0.02, random=True, n_iter=20000, random_state=1234, n_jobs=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico, results = restauration_CV('RandomOver_XGBoost_CV_Randomized20000_324000_0.02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV(dico, results, 'recall', 'f1', s=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV(dico, results, 'recall', 'f3', s=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV(dico, results, 'recall', 'f5', s=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV(dico, results, 'recall', 'precision', s=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_3scores_CV(dico, results, 'recall', 'precision', 'f1', s=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_3scores_CV(dico, results, 'f1', 'f3', 'f5', s=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_param_CV(dico, results, ncols=2, height=3.5, width=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best_score_CV(dico, results, 'f3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params['model__n_jobs'] = -1\n",
    "PARAMS[dico['model_name']] = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X, y, pipeline.set_params(**best_params))\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. GridSearchCV avec SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr1 = restauration_CV('XGBoost_CV_Randomized10000_54000_0.02', verbose=False)\n",
    "dr2 = restauration_CV('RandomOver_XGBoost_CV_Randomized20000_324000_0.02', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV_comp([dr2, dr1], 'recall', 'f3', s=[0.5, 1], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV_comp([dr2, dr1], 'recall', 'precision', s=[1, 2], alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. XGBoost avec RFECV\n",
    "### 4.1. Sans oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"backups/RFECV_XGBoost.json\", 'r') as f:\n",
    "    export = json.load(f)\n",
    "    columns_quant_RFECV = export['columns_quant']\n",
    "    columns_cat_RFECV = export['columns_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(booster='gbtree', objective='binary:logistic', n_jobs=1)\n",
    "\n",
    "cv_params = {\n",
    "        'n_estimators': [50, 100, 150, 200, 300],    \n",
    "        'max_depth': [2, 4, 6, 8, 10],\n",
    "        'learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'min_child_weight': [1, 3, 5, 10],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],    \n",
    "        'scale_pos_weight': [1, 16.5]   # A typical value to consider: sum(negative instances) / sum(positive instances)\n",
    "        }\n",
    "\n",
    "print(len(ParameterGrid(cv_params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SearchCV(model, cv_params, columns_quant=columns_quant_RFECV, columns_cat=columns_cat_RFECV, data_frac=0.02, random=True, n_iter=10000, random_state=1234, n_jobs=28, name='RFECV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico, results = restauration_CV('XGBoost_RFECV_CV_Randomized10000_54000_0.02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best_score_CV(dico, results, 'f3', display_table=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params['n_jobs'] = -1\n",
    "PARAMS[dico['model_name']] = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_df_RFECV = datasets(df, columns_quant=columns_quant_RFECV, columns_cat=columns_cat_RFECV)\n",
    "X_RFECV = datasets_df_RFECV['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X_RFECV, y, XGBClassifier(**best_params))\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Avec oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = RandomOverSampler(random_state=1234)\n",
    "\n",
    "pipeline = Pipeline_imb([\n",
    "            ('over', over),\n",
    "            ('model', XGBClassifier(booster='gbtree', objective='binary:logistic', n_jobs=1))\n",
    "            ])\n",
    "\n",
    "cv_params = {\n",
    "        \"over__sampling_strategy\": [0.1, 0.2, 0.4, 0.6, 0.8, 1],\n",
    "        \"model__n_estimators\": [50, 100, 150, 200, 300],    \n",
    "        \"model__max_depth\": [2, 4, 6, 8, 10],\n",
    "        \"model__learning_rate\": [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "        \"model__gamma\": [0.5, 1, 1.5, 2, 5],\n",
    "        \"model__min_child_weight\": [1, 3, 5, 10],\n",
    "        \"model__subsample\": [0.6, 0.8, 1.0],\n",
    "        \"model__colsample_bytree\": [0.6, 0.8, 1.0],    \n",
    "        \"model__scale_pos_weight\": [1, 16.5]   # A typical value to consider: sum(negative instances) / sum(positive instances)\n",
    "        }\n",
    "\n",
    "print(len(ParameterGrid(cv_params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SearchCV(pipeline, cv_params, columns_quant=columns_quant_RFECV, columns_cat=columns_cat_RFECV, data_frac=0.02, random=True, n_iter=20000, random_state=1234, n_jobs=28, name='RFECV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico, results = restauration_CV('RandomOver_XGBoost__RFECV_CV_Randomized20000_324000_0.02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best_score_CV(dico, results, 'f3', display_table=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params['model__n_jobs'] = -1\n",
    "PARAMS[dico['model_name']] = best_params\n",
    "with open(f\"backups/PARAMS_XGBoost.json\", 'w') as f:\n",
    "    json.dump(PARAMS, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Modelisation(X, y, pipeline.set_params(**best_params))\n",
    "m.show_conf_matrix()\n",
    "m.show_metrics_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr1 = restauration_CV('XGBoost_CV_Randomized10000_54000_0.02', verbose=False)\n",
    "dr2 = restauration_CV('XGBoost_RFECV_CV_Randomized10000_54000_0.02', verbose=False)\n",
    "dr3 = restauration_CV('RandomOver_XGBoost_CV_Randomized20000_324000_0.02', verbose=False)\n",
    "dr4 = restauration_CV('RandomOver_XGBoost__RFECV_CV_Randomized20000_324000_0.02', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV_comp([dr1, dr2], 'recall', 'f3', s=[1, 1], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV_comp([dr1, dr2], 'recall', 'precision', s=[2, 2], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV_comp([dr3, dr4], 'recall', 'f3', s=[0.5, 0.5], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2scores_CV_comp([dr3, dr4], 'recall', 'precision', s=[1, 1], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Temps d'exécution total : {time.strftime('%H:%M:%S', time.gmtime(time.time()-t))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
